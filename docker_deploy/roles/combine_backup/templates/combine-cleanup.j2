#!/bin/bash

######################################################
# Script to delete old backups from the AWS S3 bucket
######################################################

set -e

usage() {
  cat <<USAGE
  Usage: $0 [options]
     Creates a backup of the combine database and backend containers
  Options:
     -h, --help:
           print this message

     -f, --filter FILTER_STRING:
           set FILTER_STRING that is used to select the backups to be deleted.
           By default, the filter is set to the name of the current host machine
           with '.' replaced by '-' characters.
           Alternately, you may export the environment variable BACKUP_FILTER to
           specify the selection string.

     -l, --list:
           list all backups that are in the S3 bucket;
           no backups are deleted.

     -n, -num_backups NUMBER:
           number of backups to keep for the host being cleaned up
           Alternately, you may also export the environment variable MAX_BACKUPS
           to specify the number of backups to keep.
  Caveats:
    This script assumes that the backups have been created by the combine-backup
    script; specifically, that:
      1. The name of the backup is of the form:
          hostname-date.tar.gz
      2. Periods in the hostname are converted to dashes
      3. When the backups are sorted by name, they are in chronological order
         with the oldest backup first.
USAGE
}

LIST_ONLY="0"
while [[ $# -gt 0 ]] ; do
  arg="$1"
  shift

  case ${arg} in
    -h|--help)
      usage
      exit 0
      ;;
    -f|--filter)
      BACKUP_FILTER=$(echo "$1"| sed "s/\./-/g")
      shift
      ;;
    -l|--list)
      LIST_ONLY="1"
      ;;
    -n|--num-backups)
      MAX_BACKUPS=$1
      shift
      ;;
    -?)
      echo "Invalid option: ${arg}."
      usage
      exit 2
      ;;
    *)
      echo "Unrecognized argument: ${arg}"
      usage
      exit 1
      ;;
  esac
done

DATE_STR=`date +%Y-%m-%d-%H-%M-%S`
BACKUP_FILTER=${BACKUP_FILTER:="{{ combine_server_name | replace('.', '-') }}"}
AWS_BUCKET="s3://{{ aws_s3_backup_loc }}"
MAX_BACKUPS=${MAX_BACKUPS:={{ num_backups }}}

if [ "${LIST_ONLY}" = "1" ] ; then
  echo "Listing backups for s3://{{ aws_s3_backup_loc }}"
  aws s3 ls ${AWS_BUCKET} --recursive --profile s3_read_write
  exit 0
fi

AWS_BACKUPS=($(aws s3 ls ${AWS_BUCKET} --recursive --profile s3_read_write|grep --fixed-strings "${BACKUP_FILTER}"|sed "s/[^\/]*\/\(.*\)/\1/"|sort))
NUM_BACKUPS=${{ '{#' }}AWS_BACKUPS[@]}

if [[ ${NUM_BACKUPS} -gt ${MAX_BACKUPS} ]] ; then
  loop_limit=$(( ${NUM_BACKUPS} - ${MAX_BACKUPS} ))

  for (( bu=0; bu < $loop_limit; bu++ )) ; do
    aws s3 rm ${AWS_BUCKET}/${AWS_BACKUPS[${bu}]} --profile s3_read_write
  done
fi
