#!/bin/bash

DATE_STR=`date +%Y-%m-%d-%T`
COMBINE_HOST={{ ansible_hostname }}
BACKUP_FILE="combine-backup-${DATE_STR}.tar.gz"
AWS_FILE="s3://{{ aws_s3_backup_loc }}/${COMBINE_HOST}-${DATE_STR}.tar.gz"
COMBINE_HOME=${COMBINE_HOME:="/home/combine"}
BACKUP_DIR="${COMBINE_HOME}/backups"

if [ ! -e "${BACKUP_DIR}" ] ; then
  mkdir ${BACKUP_DIR}
fi

cd ${COMBINE_HOME}
# Dump the database - use default output directory, 'dump'
mongodump --db CombineDatabase --gzip --quiet
# Create compressed tarball of the database dump and the backend files
tar czf ${BACKUP_DIR}/${BACKUP_FILE} dump .CombineFiles

# Cleanup
# Remove the dump files
if [ -e dump ] ; then
  rm -rf dump
fi

# Remove old backups
cd ${BACKUP_DIR}
ALL_BACKUPS=(`ls combine-backup*.tar.gz`)

for bu in "${ALL_BACKUPS[@]}"; do
  if [ "$bu" != "$BACKUP_FILE" ] ; then
	  echo "Removing $bu"
    rm $bu
  fi
done

# if aws-cli is installed, push backup to AWS S3 storage
# need to specify full path because $PATH does not contain
# /usr/local/bin when run as a cron job
if [ -e /usr/local/bin/aws ] ; then
  /usr/local/bin/aws s3 cp ${BACKUP_FILE} ${AWS_FILE} --profile {{ aws_s3_profile }}
fi
